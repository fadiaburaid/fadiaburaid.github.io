<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
        <title>AI Avatar Resume</title>

        <link
            href="https://fonts.googleapis.com/css2?family=Exo:wght@400;500;600;700&display=swap"
            rel="stylesheet"
        />
        <script src="https://cdn.socket.io/4.1.2/socket.io.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad/dist/index.browser.js"></script>
		<script async src="{{ url_for('static', filename='js/es-module-shims.js') }}"></script>

        <style>
            body {
                font-family: sans-serif;
                font-family: "Exo", sans-serif;
                background: #000000;
                color: white;
            }
            h1 {
                text-align: center;
                font-weight: lighter;
            }
            textarea {
                display: block;
                margin: 0 auto;
                width: 100%;
				height: 300px;
                rows: 3;
                padding: 10px;
                font-size: 2rem;
				text-align: center;
                background: #000000;
                color: white;
                font-family: "Exo", sans-serif;
                border: none;
                border-radius: 5px;
                pointer-events: none;
            }
			canvas {
				padding-left: 0;
				padding-right: 0;
				margin-left: auto;
				margin-right: auto;
				display: block;
			}
			button {
			  position:fixed;
			  top:0;
			  left:0;
			  z-index:1;
			  width:100%;
			  height:100%;
			  background:rgba(77,77,77,.4);
			  font-size: 3rem;
			  font-weight: bold;
			  display: none;
			}
			#loading-screen {
				position: absolute;
				z-index: 2;
				top: 0;
				left: 0;
				width: 100%;
				height: 100%;
				background-color: #000000;
				opacity: 1;
				transition: 1s opacity;
			}

			#loading-screen.fade-out {
				opacity: 0;
			}

			#loader {
				display: block;
				position: relative;
				left: 50%;
				top: 50%;
				width: 150px;
				height: 150px;
				margin: -75px 0 0 -75px;
				border-radius: 50%;
				border: 3px solid transparent;
				border-top-color: #9370DB;
				-webkit-animation: spin 2s linear infinite;
				animation: spin 2s linear infinite;
			}
			#loader:before {
				content: "";
				position: absolute;
				top: 5px;
				left: 5px;
				right: 5px;
				bottom: 5px;
				border-radius: 50%;
				border: 3px solid transparent;
				border-top-color: #BA55D3;
				-webkit-animation: spin 3s linear infinite;
				animation: spin 3s linear infinite;
			}
			#loader:after {
				content: "";
				position: absolute;
				top: 15px;
				left: 15px;
				right: 15px;
				bottom: 15px;
				border-radius: 50%;
				border: 3px solid transparent;
				border-top-color: #FF00FF;
				-webkit-animation: spin 1.5s linear infinite;
				animation: spin 1.5s linear infinite;
			}
			@-webkit-keyframes spin {
				0%   {
					-webkit-transform: rotate(0deg);
					-ms-transform: rotate(0deg);
					transform: rotate(0deg);
				}
				100% {
					-webkit-transform: rotate(360deg);
					-ms-transform: rotate(360deg);
					transform: rotate(360deg);
				}
			}
			@keyframes spin {
				0%   {
					-webkit-transform: rotate(0deg);
					-ms-transform: rotate(0deg);
					transform: rotate(0deg);
				}
				100% {
					-webkit-transform: rotate(360deg);
					-ms-transform: rotate(360deg);
					transform: rotate(360deg);
				}
			}
        </style>
    </head>
    <body>
        <h1>AI Avatar Resume</h1>
		<section id="loading-screen">
			<div id="loader"></div>
		</section>
		<button type="button" id="myBtn">Click To Begin</button>
		<canvas id="avatarCanvas"></canvas>
        <p id="status"></p>
        <textarea id="output"></textarea>
    </body>

	<script type="importmap">
		{
			"imports": {
				"three": "https://threejs.org/build/three.module.js",
				"three/addons/": "./jsm/"
			}
		}
	</script>
	<script type="module">
		import * as THREE from 'three';

		//import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
		import { RoomEnvironment } from 'three/addons/environments/RoomEnvironment.js';

		import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
		import { KTX2Loader } from 'three/addons/loaders/KTX2Loader.js';
		import { MeshoptDecoder } from 'three/addons/libs/meshopt_decoder.module.js';

		import { GUI } from 'three/addons/libs/lil-gui.module.min.js';

		const blendshapesMap = {
			// '_neutral': '',
			'browDownLeft': 'browDownLeft',
			'browDownRight': 'browDownRight',
			'browInnerUp': 'browInnerUp',
			'browOuterUpLeft': 'browOuterUpLeft',
			'browOuterUpRight': 'browOuterUpRight',
			'cheekPuff': 'cheekPuff',
			'cheekSquintLeft': 'cheekSquintLeft',
			'cheekSquintRight': 'cheekSquintRight',
			'eyeBlinkLeft': 'eyeBlinkLeft',
			'eyeBlinkRight': 'eyeBlinkRight',
			'eyeLookDownLeft': 'eyeLookDownLeft',
			'eyeLookDownRight': 'eyeLookDownRight',
			'eyeLookInLeft': 'eyeLookInLeft',
			'eyeLookInRight': 'eyeLookInRight',
			'eyeLookOutLeft': 'eyeLookOutLeft',
			'eyeLookOutRight': 'eyeLookOutRight',
			'eyeLookUpLeft': 'eyeLookUpLeft',
			'eyeLookUpRight': 'eyeLookUpRight',
			'eyeSquintLeft': 'eyeSquintLeft',
			'eyeSquintRight': 'eyeSquintRight',
			'eyeWideLeft': 'eyeWideLeft',
			'eyeWideRight': 'eyeWideRight',
			'jawForward': 'jawForward',
			'jawLeft': 'jawLeft',
			'jawOpen': 'jawOpen',
			'jawRight': 'jawRight',
			'mouthClose': 'mouthClose',
			'mouthDimpleLeft': 'mouthDimpleLeft',
			'mouthDimpleRight': 'mouthDimpleRight',
			'mouthFrownLeft': 'mouthFrownLeft',
			'mouthFrownRight': 'mouthFrownRight',
			'mouthFunnel': 'mouthFunnel',
			'mouthLeft': 'mouthLeft',
			'mouthLowerDownLeft': 'mouthLowerDownLeft',
			'mouthLowerDownRight': 'mouthLowerDownRight',
			'mouthPressLeft': 'mouthPressLeft',
			'mouthPressRight': 'mouthPressRight',
			'mouthPucker': 'mouthPucker',
			'mouthRight': 'mouthRight',
			'mouthRollLower': 'mouthRollLower',
			'mouthRollUpper': 'mouthRollUpper',
			'mouthShrugLower': 'mouthShrugLower',
			'mouthShrugUpper': 'mouthShrugUpper',
			'mouthSmileLeft': 'mouthSmileLeft',
			'mouthSmileRight': 'mouthSmileRight',
			'mouthStretchLeft': 'mouthStretchLeft',
			'mouthStretchRight': 'mouthStretchRight',
			'mouthUpperUpLeft': 'mouthUpperUpLeft',
			'mouthUpperUpRight': 'mouthUpperUpRight',
			'noseSneerLeft': 'noseSneerLeft',
			'noseSneerRight': 'noseSneerRight',
			// '': 'tongueOut'
		};
		// get reference to button
	    var btn = document.getElementById("myBtn");
	    // add event listener for the button, for action "click"
	    btn.addEventListener("click", welcome);
		//
		
		const renderer = new THREE.WebGLRenderer( { canvas: avatarCanvas } );
		renderer.setPixelRatio( window.devicePixelRatio );
		renderer.setSize( window.innerWidth/1.3, window.innerHeight/1.3);
		renderer.toneMapping = THREE.ACESFilmicToneMapping;

		const camera = new THREE.PerspectiveCamera( 35, window.innerWidth/window.innerHeight, 1, 100 );
		camera.position.set( -0.6, 1.5, 2);	
		//camera.position.z = 5;
		let mixer,clips,actions, activeAction, previousAction;
		let clock = new THREE.Clock();

		const scene = new THREE.Scene();
		scene.scale.x = - 1;
		var speed=0.01, mesh;
		const environment = new RoomEnvironment();
		const pmremGenerator = new THREE.PMREMGenerator( renderer );
		const loader = new THREE.TextureLoader();
		scene.background = loader.load( "jsm/data/office.jpg" );
		//scene.background = new THREE.Color( 0x666666 );
		scene.environment = pmremGenerator.fromScene( environment ).texture;

		//const controls = new OrbitControls( camera, renderer.domElement );

		// Face

		const ktx2Loader = new KTX2Loader()
			.setTranscoderPath( "./basis/" )
			.detectSupport( renderer );

		let head,eye,teeth,eyelash;
		
		const loadingManager = new THREE.LoadingManager( () => {
	
			const loadingScreen = document.getElementById( 'loading-screen' );
			loadingScreen.classList.add( 'fade-out' );
			
			// optional: remove loader from DOM via event listener
			loadingScreen.addEventListener( 'transitionend', onTransitionEnd );
			
		} );
		const loading = new GLTFLoader( loadingManager );
		
		loading.setKTX2Loader( ktx2Loader )
			.setMeshoptDecoder( MeshoptDecoder )
			.load( "./avatars/fadi_real.glb", ( gltf ) => {

				mesh = gltf.scene.children[ 0 ];
				scene.add( mesh );
				
				mixer = new THREE.AnimationMixer( mesh );
				clips = gltf.animations;
				
				
				actions = {};
				for ( let i = 0; i < clips.length; i ++ ) {

					const clip = clips[ i ];
					const action = mixer.clipAction( clip );
					actions[ clip.name ] = action;

				}


				//idle1,idle2,idle3,talking1,talking2,talking3,thinking
				//idle1 = mixer.clipAction( clips[0] );
				//talk2 = mixer.clipAction( clips[5] );
				
				var walk_turn = function(){
				  activeAction=actions[ 'walking1' ];
				  activeAction.play();
				  setTimeout(function(){
				  fadeToAction( "turn_left",1);
				  activeAction.setLoop(THREE.LoopOnce, 1);
				  }, 1500);
				  setTimeout(function(){
				  activeAction=actions[ 'idle1' ];
				  activeAction.play();
				  btn.style.display = 'block';
				  }, 2200);
				};
				walk_turn();
				//activeAction=actions[ 'walking1' ];
				//activeAction.play();
				//fadeToAction( "turn_left",4);
				//activeAction.setLoop(THREE.LoopOnce, 1);
				//fadeToAction( "turn_left", 5 );
				//fadeToAction( "idle1", 1 );
				//activeAction.setLoop(THRE E.LoopRepeat, 1);
				//const head = mesh.getObjectByName( 'Wolf3D_Avatar' );
				head = mesh.getObjectByName( 'Head_Mesh' );
				eye = mesh.getObjectByName( 'Eye_Mesh' );
				teeth = mesh.getObjectByName( 'Teeth_Mesh' );
				eyelash = mesh.getObjectByName( 'Eyelash_Mesh' );
				/*
				// GUI
				
				const gui = new GUI();
				gui.close();

				const influences = head.morphTargetInfluences;

				for ( const [ key, value ] of Object.entries( head.morphTargetDictionary ) ) {

					gui.add( influences, value, 0, 1, 0.01 )
						.name( key.replace( 'blendShape1.', '' ) )
						.listen( influences );

				}
				*/
				
				const values1 = [ 0,0.5,0,0];
				const values2 = [ 0,0,0,0.5];
				
				let i=0;
				var blink = function(){
				  //close the eyes
				  head.morphTargetInfluences[65] = 1;
				  head.morphTargetInfluences[66] = 1;
				  eyelash.morphTargetInfluences[21] = 1;
				  eyelash.morphTargetInfluences[22] = 1;
				  setTimeout(function(){
					//open them again
				  head.morphTargetInfluences[65] = 0;
				  head.morphTargetInfluences[66] = 0;
				  eyelash.morphTargetInfluences[21] = 0;
				  eyelash.morphTargetInfluences[22] = 0;
				  }, 200);
				  eye.morphTargetInfluences[4] = values1[i]; // left eye look in
				  eye.morphTargetInfluences[7] = values1[i]; //right eye look out
				  eye.morphTargetInfluences[6] = values2[i]; // left eye look out
				  eye.morphTargetInfluences[5]= values2[i]; // right eye look in
				  i++;
				  if (i == values1.length) {
					i = 0;
				  }
				};

				setInterval(blink, 3000);
									
				renderer.setAnimationLoop( animation );

			} );
			
		function animation() {
			
			if (mesh.position.x < 0.6) {
				mesh.translateX( speed );
			}

			const mixerUpdateDelta = clock.getDelta();
			mixer.update( mixerUpdateDelta );


			renderer.render( scene, camera );

			//controls.update();

		}	
		
		function onWindowResize() {

			camera.aspect = window.innerWidth / window.innerHeight;
			camera.updateProjectionMatrix();

			renderer.setSize( window.innerWidth/1.3, window.innerHeight/1.3 );

		}
		
		function onTransitionEnd( event ) {

			event.target.remove();
	
		}
		
		const output = document.getElementById("output");
        const status = document.getElementById("status");
		var socket,myvad,wavBuffer;
		var audio = new Audio("./jsm/data/speech.wav");	
		audio.load
		
        async function main() {
			
            socket = io()

            socket.on("connect", async () => {
                myvad = await vad.MicVAD.new({
                    positiveSpeechThreshold: 0.8,
                    negativeSpeechThreshold: 0.8 - 0.15,
                    minSpeechFrames: 2,
                    preSpeechPadFrames: 8,
                    redemptionFrames: 3,
                    onSpeechStart: () => {
                        console.log("Speech start detected");
                        status.innerText = "Listening";
						activeAction.fadeOut( 1 );
						activeAction = actions[ "thinking"];
						activeAction.setLoop(THREE.LoopOnce);
						activeAction.clampWhenFinished = true;
						activeAction
						.reset()
						.setEffectiveTimeScale( 0.8 )
						.setEffectiveWeight( 1 )
						.fadeIn( 1 )
						.play();

                    },
                    onSpeechEnd: (audio) => {
						fadeToAction( "idle1", 1 );
						myvad.pause();
                        status.innerText = "Processing...";
                        wavBuffer = vad.utils.encodeWAV(audio);
                        const base64 = vad.utils.arrayBufferToBase64(wavBuffer);
                        socket.emit("audio_data", base64);
                    },
                });
                myvad.start();
            });
            socket.on("transcription", (data) => {
                status.innerText = "";
                output.value = (data)
                    .replace(".", " ")
                    .replace("  ", " ");
            });
			
			socket.on("reply", (data) => {
                status.innerText = "";
                output.value = (output.value + data)
                    .replace(".", " ")
                    .replace("  ", " ");
			
				/*
				const url = "{{ url_for('static', filename='visemes.txt')}}";
				fetch(url)
				   .then( r => r.text() )
				   .then( t => process_visemes(t))
				
				audio = new Audio("./static/speech.wav?cb=" + new Date().getTime());				
				audio.load();
				*/
            });
			socket.on("audio", (data) => {
				audio = new Audio("data:audio/wav;base64," + data);				
            });
			
			socket.on("visemes", (data) => {
				process_visemes(data)
            });
			
        }
        
		let count,playvsms,smile,dismile;
		let ocls_phnms=[];
		function process_visemes(jali_vsms) {
        let splitLines = jali_vsms.split(/\r?\n/);
		for (let r = 0; r < splitLines.length; r++) {
			let jali_phnms=splitLines[r].split(",").map(function(item){
			  return item.trim();
			});;
			ocls_phnms[r]=[0,Number(jali_phnms[19]),Number(jali_phnms[20]),Number(jali_phnms[15]),0,Number(jali_phnms[18]),(Number(jali_phnms[16])+Number(jali_phnms[14]))/2,Number(jali_phnms[13]),Number(jali_phnms[17]),Number(jali_phnms[12]),(Number(jali_phnms[2])+Number(jali_phnms[3]))/2,(Number(jali_phnms[4])+Number(jali_phnms[5])+Number(jali_phnms[10])+Number(jali_phnms[11]))/4,Number(jali_phnms[6]),Number(jali_phnms[7]),(Number(jali_phnms[8])+Number(jali_phnms[9]))/2];
		}
		count=0;
		playvsms=setInterval(play_visemes, 10);
		audio.play();
		fadeToAction( "talking3", 1 );
		smile=setInterval(smile_t, 50);
		}
		
		function smile_t(){
		if (head.morphTargetInfluences[62] < 0.4){
		head.morphTargetInfluences[62] = head.morphTargetInfluences[62] + 0.05;
		head.morphTargetInfluences[63] = head.morphTargetInfluences[63] + 0.05;
		}
		else{
		clearInterval(smile);
		}
		}
		
		function dismile_t(){
		if (head.morphTargetInfluences[62] > 0){
		head.morphTargetInfluences[62] = head.morphTargetInfluences[62] - 0.05;
		head.morphTargetInfluences[63] = head.morphTargetInfluences[63] - 0.05;
		}
		else{
		clearInterval(dismile);
		}
		}
		
		function play_visemes(){
			for (let i = 0; i < 15; i++) {
				head.morphTargetInfluences[ i ] = ocls_phnms[count][i];
				teeth.morphTargetInfluences[ i ] = ocls_phnms[count][i];
			}
			count++;
			if (count == ocls_phnms.length-1){
				clearInterval(playvsms);
				fadeToAction( "idle1", 1 );
				dismile=setInterval(dismile_t, 50);
				for (let i = 0; i < 15; i++) {
					head.morphTargetInfluences[ i ] = 0;
					teeth.morphTargetInfluences[ i ] = 0;
				}
				ocls_phnms=[];
				if (typeof myvad !== 'undefined') {
				myvad.start();
				}
			}
		}
		
		function welcome(){
		btn.style.display = 'none';
	
		output.value = "Hello, I am happy to be interviewed by you."
		setTimeout(function(){output.value = "You may ask me questions about myself, my education and work history."}, 3000); 
		setTimeout(function(){output.value = "I will give you the answers to the best of my knowledge."}, 8000); 
		setTimeout(main, 9000); 
		const url = "./jsm/data/visemes.txt";
			fetch(url)
				.then( r => r.text() )
				.then( t => process_visemes(t))	
		}
				
		function fadeToAction( name, duration ) {

				previousAction = activeAction;
				activeAction = actions[ name ];

				if ( previousAction !== activeAction ) {

					previousAction.fadeOut( duration );

				}

				activeAction
					.reset()
					.setEffectiveTimeScale( 1 )
					.setEffectiveWeight( 1 )
					.fadeIn( duration )
					.play();

			}

	</script>


</html>
